{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44698d73",
   "metadata": {},
   "source": [
    "# Improve Coffee Dataset quality with SAM2 in FiftyOne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb1a8a4",
   "metadata": {},
   "source": [
    "## üèÜ Learning Objectives\n",
    "- Understand how to apply the SAM2 segmentation model.\n",
    "- Learn how to integrate SAM2 with FiftyOne.\n",
    "- Visualize segmentation results using FiftyOne.\n",
    "- Improve the dataset quality with Uniqueness features with FiftyOne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c53e89",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "### Knowledge\n",
    "- Understanding of image segmentation.\n",
    "- Familiarity with deep learning-based annotation tools.\n",
    "### Installation\n",
    "Run the following commands to install necessary dependencies:\n",
    "```bash\n",
    "git clone https://github.com/facebookresearch/sam2.git && cd sam2\n",
    "pip install -e .\n",
    "pip install fiftyone\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8818e3a1",
   "metadata": {},
   "source": [
    "## 1. Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79079143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading config file fiftyone.yml from pjramg/my_colombian_coffe_FO\n",
      "Loading dataset\n",
      "Importing samples...\n",
      " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1593/1593 [28.4ms elapsed, 0s remaining, 56.0K samples/s]   \n",
      "Dataset 'coffee_FO_SAM2_process' exists. Loading...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import fiftyone as fo # base library and app\n",
    "import fiftyone.utils.huggingface as fouh # Hugging Face integration\n",
    "dataset_ = fouh.load_from_hub(\"pjramg/my_colombian_coffe_FO\", persistent=True, overwrite=True)\n",
    "#dataset = fo.load_dataset(\"Voxel51/mvtec-ad\") # Use this CLI if you already have the dataset \n",
    "                                               # in your disk or if this is not the first time you run this notebook \n",
    "\n",
    "# Define the new dataset name\n",
    "dataset_name = \"coffee_FO_SAM2_process\"\n",
    "\n",
    "# Check if the dataset exists\n",
    "if dataset_name in fo.list_datasets():\n",
    "    print(f\"Dataset '{dataset_name}' exists. Loading...\")\n",
    "    dataset = fo.load_dataset(dataset_name)\n",
    "else:\n",
    "    print(f\"Dataset '{dataset_name}' does not exist. Creating a new one...\")\n",
    "    # Clone the dataset with a new name and make it persistent\n",
    "    dataset = dataset_.clone(dataset_name, persistent=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85402f9",
   "metadata": {},
   "source": [
    "## 2. Applying the SAM2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364fe6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone.zoo as foz\n",
    "model = foz.load_zoo_model(\"segment-anything-2-hiera-tiny-image-torch\")\n",
    "# Prompt with boxes\n",
    "dataset.apply_model(\n",
    "    model,\n",
    "    label_field=\"segmentations\",\n",
    "    prompt_field=\"categories_segmentations\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualizing the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:        coffee_FO_SAM2_process\n",
      "Media type:  image\n",
      "Num samples: 1593\n",
      "Persistent:  True\n",
      "Tags:        []\n",
      "Sample fields:\n",
      "    id:                       fiftyone.core.fields.ObjectIdField\n",
      "    filepath:                 fiftyone.core.fields.StringField\n",
      "    tags:                     fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
      "    metadata:                 fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
      "    created_at:               fiftyone.core.fields.DateTimeField\n",
      "    last_modified_at:         fiftyone.core.fields.DateTimeField\n",
      "    categories_coco_id:       fiftyone.core.fields.IntField\n",
      "    categories_segmentations: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    segmentations:            fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "Dataset sample labels:\n",
      "<Sample: {\n",
      "    'id': '67892eeb3adf1dd0f587f860',\n",
      "    'media_type': 'image',\n",
      "    'filepath': '/home/paula/fiftyone/huggingface/hub/pjramg/my_colombian_coffe_FO/data/lin_ln_20150617_102755_im_01.jpg',\n",
      "    'tags': [],\n",
      "    'metadata': <ImageMetadata: {\n",
      "        'size_bytes': None,\n",
      "        'mime_type': None,\n",
      "        'width': 1920,\n",
      "        'height': 1080,\n",
      "        'num_channels': None,\n",
      "    }>,\n",
      "    'created_at': datetime.datetime(2025, 3, 17, 14, 44, 27, 335000),\n",
      "    'last_modified_at': datetime.datetime(2025, 3, 17, 14, 44, 27, 335000),\n",
      "    'categories_coco_id': 1,\n",
      "    'categories_segmentations': None,\n",
      "    'segmentations': None,\n",
      "}>\n",
      "Session launched. Run `session.show()` to open the App in a cell output.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fiftyone.core.session.session:Session launched. Run `session.show()` to open the App in a cell output.\n"
     ]
    }
   ],
   "source": [
    "# Print dataset summary\n",
    "print(dataset)\n",
    "\n",
    "# Show some random samples\n",
    "print(\"Dataset sample labels:\")\n",
    "print(dataset.first())\n",
    "\n",
    "session = fo.launch_app(dataset, port=5161, auto=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d464b2e1",
   "metadata": {},
   "source": [
    "## 4. Find Uniqueness images\n",
    "\n",
    "How to use uniqueness detection, similarity search, and embedding visualizations for agricultural AI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0b38ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fiftyone.brain.internal.core.utils:Computing embeddings...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1593/1593 [30.8s elapsed, 0s remaining, 52.2 samples/s]      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:eta.core.utils: 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1593/1593 [30.8s elapsed, 0s remaining, 52.2 samples/s]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing unique samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fiftyone.brain.similarity:Computing unique samples...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating index for 1593 embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fiftyone.brain.internal.core.sklearn:Generating index for 1593 embeddings...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fiftyone.brain.internal.core.sklearn:Index complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold: 1.000000, kept: 5, target: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fiftyone.brain.similarity:threshold: 1.000000, kept: 5, target: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold: 0.500000, kept: 64, target: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fiftyone.brain.similarity:threshold: 0.500000, kept: 64, target: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold: 0.250000, kept: 184, target: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fiftyone.brain.similarity:threshold: 0.250000, kept: 184, target: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold: 0.375000, kept: 106, target: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fiftyone.brain.similarity:threshold: 0.375000, kept: 106, target: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold: 0.437500, kept: 84, target: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fiftyone.brain.similarity:threshold: 0.437500, kept: 84, target: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold: 0.406250, kept: 98, target: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fiftyone.brain.similarity:threshold: 0.406250, kept: 98, target: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold: 0.390625, kept: 99, target: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fiftyone.brain.similarity:threshold: 0.390625, kept: 99, target: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold: 0.382812, kept: 104, target: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fiftyone.brain.similarity:threshold: 0.382812, kept: 104, target: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold: 0.386719, kept: 101, target: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fiftyone.brain.similarity:threshold: 0.386719, kept: 101, target: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold: 0.388672, kept: 99, target: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fiftyone.brain.similarity:threshold: 0.388672, kept: 99, target: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold: 0.387695, kept: 101, target: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fiftyone.brain.similarity:threshold: 0.387695, kept: 101, target: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold: 0.388184, kept: 100, target: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fiftyone.brain.similarity:threshold: 0.388184, kept: 100, target: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniqueness computation complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fiftyone.brain.similarity:Uniqueness computation complete\n"
     ]
    }
   ],
   "source": [
    "import fiftyone.brain as fob\n",
    "\n",
    "results = fob.compute_similarity(dataset, brain_key=\"img_sim\")\n",
    "results.find_unique(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea04d931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fiftyone.brain.internal.core.utils:Computing embeddings...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1593/1593 [30.8s elapsed, 0s remaining, 55.0 samples/s]      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:eta.core.utils: 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1593/1593 [30.8s elapsed, 0s remaining, 55.0 samples/s]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fiftyone.brain.visualization:Generating visualization...\n",
      "2025-03-17 10:53:14.747127: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-17 10:53:14.849674: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742223194.887693    5841 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742223194.899174    5841 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-17 10:53:15.010614: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/paula/projects/databricks/coffee_workshop_env/lib/python3.10/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/home/paula/projects/databricks/coffee_workshop_env/lib/python3.10/site-packages/numba/np/ufunc/parallel.py:371: NumbaWarning: The TBB threading layer requires TBB version 2021 update 6 or later i.e., TBB_INTERFACE_VERSION >= 12060. Found TBB_INTERFACE_VERSION = 12050. The TBB threading layer is disabled.\n",
      "  warnings.warn(problem)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP( verbose=True)\n",
      "Mon Mar 17 10:53:16 2025 Construct fuzzy simplicial set\n",
      "Mon Mar 17 10:53:17 2025 Finding Nearest Neighbors\n",
      "Mon Mar 17 10:53:20 2025 Finished Nearest Neighbor Search\n",
      "Mon Mar 17 10:53:21 2025 Construct embedding\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85eec53cb9f5463f897e6812e6b51ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs completed:   0%|            0/500 [00:00]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcompleted  0  /  500 epochs\n",
      "\tcompleted  50  /  500 epochs\n",
      "\tcompleted  100  /  500 epochs\n",
      "\tcompleted  150  /  500 epochs\n",
      "\tcompleted  200  /  500 epochs\n",
      "\tcompleted  250  /  500 epochs\n",
      "\tcompleted  300  /  500 epochs\n",
      "\tcompleted  350  /  500 epochs\n",
      "\tcompleted  400  /  500 epochs\n",
      "\tcompleted  450  /  500 epochs\n",
      "Mon Mar 17 10:53:22 2025 Finished embedding\n"
     ]
    }
   ],
   "source": [
    "vis_results = fob.compute_visualization(dataset, brain_key=\"img_vis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35b9333d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model from Google Drive ID '1SIO9XreK0w1ja4EuhBWcR10CnWxCOsom'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fiftyone.core.models:Downloading model from Google Drive ID '1SIO9XreK0w1ja4EuhBWcR10CnWxCOsom'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |‚ñà‚ñà‚ñà‚ñà|  100.6Mb/100.6Mb [357.9ms elapsed, 0s remaining, 281.0Mb/s]      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:eta.core.utils: 100% |‚ñà‚ñà‚ñà‚ñà|  100.6Mb/100.6Mb [357.9ms elapsed, 0s remaining, 281.0Mb/s]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fiftyone.brain.internal.core.utils:Computing embeddings...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1593/1593 [2.5s elapsed, 0s remaining, 902.8 samples/s]      \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:eta.core.utils: 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1593/1593 [2.5s elapsed, 0s remaining, 902.8 samples/s]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing uniqueness...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fiftyone.brain.internal.core.uniqueness:Computing uniqueness...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating index for 1593 embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fiftyone.brain.internal.core.sklearn:Generating index for 1593 embeddings...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fiftyone.brain.internal.core.sklearn:Index complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniqueness computation complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fiftyone.brain.internal.core.uniqueness:Uniqueness computation complete\n"
     ]
    }
   ],
   "source": [
    "import fiftyone.brain as fob\n",
    "\n",
    "fob.compute_uniqueness(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "463f5059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:     coffee_FO_SAM2_process\n",
      "Media type:  image\n",
      "Num samples: 100\n",
      "Sample fields:\n",
      "    id:                       fiftyone.core.fields.ObjectIdField\n",
      "    filepath:                 fiftyone.core.fields.StringField\n",
      "    tags:                     fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
      "    metadata:                 fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
      "    created_at:               fiftyone.core.fields.DateTimeField\n",
      "    last_modified_at:         fiftyone.core.fields.DateTimeField\n",
      "    categories_coco_id:       fiftyone.core.fields.IntField\n",
      "    categories_segmentations: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    segmentations:            fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    auto:                     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    polished_auto:            fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    polished_auto_export:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    uniqueness:               fiftyone.core.fields.FloatField\n",
      "View stages:\n",
      "    1. Select(sample_ids=['67892eeb3adf1dd0f587f860', '67892eeb3adf1dd0f587f91e', '67892eeb3adf1dd0f587f9cf', ...], ordered=False)\n"
     ]
    }
   ],
   "source": [
    "unique_view = dataset.select(results.unique_ids)\n",
    "session.view = unique_view\n",
    "\n",
    "print(unique_view)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321006e5",
   "metadata": {},
   "source": [
    "## 5. Pre-annoted with SAM2 in the 100 unique samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13cbeb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [2.6m elapsed, 0s remaining, 0.6 samples/s]    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:eta.core.utils: 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [2.6m elapsed, 0s remaining, 0.6 samples/s]    \n"
     ]
    }
   ],
   "source": [
    "# Full automatic segmentations\n",
    "#dataset.apply_model(model, label_field=\"auto\")\n",
    "unique_view.apply_model(model, label_field=\"auto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac22880f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session launched. Run `session.show()` to open the App in a cell output.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fiftyone.core.session.session:Session launched. Run `session.show()` to open the App in a cell output.\n"
     ]
    }
   ],
   "source": [
    "session = fo.launch_app(unique_view, port=5161, auto=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd18f1a",
   "metadata": {},
   "source": [
    "## 6. Assign labels to auto-labeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bef605f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paula/projects/databricks/coffee_workshop_env/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/paula/projects/databricks/coffee_workshop_env/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering and label assignment completed for `polished_auto`.\n"
     ]
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torchvision.models import resnet18\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load dataset\n",
    "#dataset = fo.load_dataset(\"coffee_FO\")\n",
    "\n",
    "# Ensure `polished_auto` field exists\n",
    "if \"polished_auto\" not in unique_view.get_field_schema():\n",
    "    dataset.add_sample_field(\"polished_auto\", fo.EmbeddedDocumentField, embedded_doc_type=fo.Detections)\n",
    "\n",
    "# Load a pre-trained feature extractor (ResNet18)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = resnet18(pretrained=True).eval().to(device)\n",
    "\n",
    "# Define preprocessing for the bounding box patches\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "def extract_patch(sample, bbox):\n",
    "    \"\"\" Extracts an image patch corresponding to a bounding box from a sample. \"\"\"\n",
    "    image = Image.open(sample.filepath).convert(\"RGB\")\n",
    "    img_w, img_h = image.size\n",
    "\n",
    "    # Convert relative bounding box to absolute\n",
    "    x, y, w, h = bbox\n",
    "    abs_x, abs_y, abs_w, abs_h = int(x * img_w), int(y * img_h), int(w * img_w), int(h * img_h)\n",
    "\n",
    "    # Crop and preprocess\n",
    "    patch = image.crop((abs_x, abs_y, abs_x + abs_w, abs_y + abs_h))\n",
    "    return transform(patch).unsqueeze(0).to(device)  # Add batch dimension\n",
    "\n",
    "def compute_embedding(image_patch):\n",
    "    \"\"\" Computes the feature embedding of a cropped bounding box using ResNet. \"\"\"\n",
    "    with torch.no_grad():\n",
    "        features = model(image_patch)\n",
    "    return features.cpu().numpy().flatten()  # Convert to 1D vector\n",
    "\n",
    "def compute_iou(boxA, boxB):\n",
    "    \"\"\" Computes Intersection over Union (IoU) between two bounding boxes. \"\"\"\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[0] + boxA[2], boxB[0] + boxB[2])\n",
    "    yB = min(boxA[1] + boxA[3], boxB[1] + boxB[3])\n",
    "\n",
    "    inter_area = max(0, xB - xA) * max(0, yB - yA)\n",
    "    boxA_area = boxA[2] * boxA[3]\n",
    "    boxB_area = boxB[2] * boxB[3]\n",
    "    union_area = boxA_area + boxB_area - inter_area\n",
    "\n",
    "    return inter_area / union_area if union_area > 0 else 0\n",
    "\n",
    "# Step 1: Extract ground truth information from the whole dataset (Embeddings)\n",
    "ground_truth_boxes = []\n",
    "y_positions = []\n",
    "gt_embeddings = []\n",
    "gt_labels = []\n",
    "\n",
    "for sample in dataset:\n",
    "    if sample.categories_segmentations and sample.categories_segmentations.detections:\n",
    "        for det in sample.categories_segmentations.detections:\n",
    "            bbox = det.bounding_box\n",
    "            ground_truth_boxes.append(bbox)\n",
    "            y_positions.append(bbox[1])  # Store Y positions\n",
    "            image_patch = extract_patch(sample, bbox)\n",
    "            gt_embeddings.append(compute_embedding(image_patch))\n",
    "            gt_labels.append(det.label)\n",
    "\n",
    "# Convert embeddings list to NumPy array\n",
    "gt_embeddings = np.array(gt_embeddings) if gt_embeddings else np.empty((0, 512))\n",
    "\n",
    "# Compute size and Y-axis constraints\n",
    "box_areas = [w * h for _, _, w, h in ground_truth_boxes]\n",
    "avg_box_area = np.mean(box_areas)\n",
    "std_box_area = np.std(box_areas)\n",
    "lower_size_limit = max(0, avg_box_area - 1.5 * std_box_area)\n",
    "upper_size_limit = avg_box_area + 1.5 * std_box_area\n",
    "min_y_gt = min(y_positions) if y_positions else 0\n",
    "max_y_gt = max(y_positions) if y_positions else 1\n",
    "\n",
    "# Step 2: Filter auto-generated bounding boxes\n",
    "for sample in unique_view:\n",
    "    if sample.auto and sample.auto.detections:\n",
    "        valid_detections = []\n",
    "        for detection in sample.auto.detections:\n",
    "            x, y, bw, bh = detection.bounding_box\n",
    "            area = bw * bh\n",
    "            aspect_ratio = bw / bh if bh > 0 else 1\n",
    "            is_circular = 0.25 <= aspect_ratio <= 0.8  # Keep only circular/elliptical\n",
    "\n",
    "            if (lower_size_limit <= area <= upper_size_limit and  \n",
    "                min_y_gt <= y <= max_y_gt and  \n",
    "                is_circular):  \n",
    "                valid_detections.append(detection)\n",
    "\n",
    "        # Step 3: Assign labels using embeddings\n",
    "        for det in valid_detections:\n",
    "            image_patch = extract_patch(sample, det.bounding_box)\n",
    "            embedding = compute_embedding(image_patch)\n",
    "\n",
    "            if len(gt_embeddings) > 0:\n",
    "                similarities = cosine_similarity([embedding], gt_embeddings)[0]\n",
    "                best_match_idx = np.argmax(similarities)\n",
    "                best_match_label = gt_labels[best_match_idx]\n",
    "            else:\n",
    "                best_match_label = \"unknown\"  # This should not happen\n",
    "\n",
    "            det.label = best_match_label\n",
    "\n",
    "        # Save filtered detections in `polished_auto`\n",
    "        sample[\"polished_auto\"] = fo.Detections(detections=valid_detections)\n",
    "        sample.save()\n",
    "\n",
    "print(\"Filtering and label assignment completed for `polished_auto`.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aef16d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:        coffee_FO_SAM2_process\n",
      "Media type:  image\n",
      "Num samples: 1593\n",
      "Persistent:  True\n",
      "Tags:        []\n",
      "Sample fields:\n",
      "    id:                       fiftyone.core.fields.ObjectIdField\n",
      "    filepath:                 fiftyone.core.fields.StringField\n",
      "    tags:                     fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
      "    metadata:                 fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
      "    created_at:               fiftyone.core.fields.DateTimeField\n",
      "    last_modified_at:         fiftyone.core.fields.DateTimeField\n",
      "    categories_coco_id:       fiftyone.core.fields.IntField\n",
      "    categories_segmentations: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    segmentations:            fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    auto:                     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    polished_auto:            fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    polished_auto_export:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    uniqueness:               fiftyone.core.fields.FloatField\n",
      "Dataset:     coffee_FO_SAM2_process\n",
      "Media type:  image\n",
      "Num samples: 100\n",
      "Sample fields:\n",
      "    id:                       fiftyone.core.fields.ObjectIdField\n",
      "    filepath:                 fiftyone.core.fields.StringField\n",
      "    tags:                     fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
      "    metadata:                 fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
      "    created_at:               fiftyone.core.fields.DateTimeField\n",
      "    last_modified_at:         fiftyone.core.fields.DateTimeField\n",
      "    categories_coco_id:       fiftyone.core.fields.IntField\n",
      "    categories_segmentations: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    segmentations:            fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    auto:                     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    polished_auto:            fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    polished_auto_export:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    uniqueness:               fiftyone.core.fields.FloatField\n",
      "View stages:\n",
      "    1. Select(sample_ids=['67892eeb3adf1dd0f587f860', '67892eeb3adf1dd0f587f91e', '67892eeb3adf1dd0f587f9cf', ...], ordered=False)\n"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "print(unique_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6b51cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session launched. Run `session.show()` to open the App in a cell output.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fiftyone.core.session.session:Session launched. Run `session.show()` to open the App in a cell output.\n"
     ]
    }
   ],
   "source": [
    "session = fo.launch_app(unique_view, port=5161, auto=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd42ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Duplicate `polished_auto` into `polished_auto_export`\n",
    "if \"polished_auto_export\" not in unique_view.get_field_schema():\n",
    "    unique_view.add_sample_field(\"polished_auto_export\", fo.EmbeddedDocumentField, embedded_doc_type=fo.Detections)\n",
    "\n",
    "for sample in unique_view:\n",
    "    if sample[\"polished_auto\"]:\n",
    "        sample[\"polished_auto_export\"] = sample[\"polished_auto\"].copy()  # Create a true duplicate\n",
    "    else:\n",
    "        sample[\"polished_auto_export\"] = None  # Ensure field exists\n",
    "    sample.save()\n",
    "\n",
    "print(\"Duplicated `polished_auto` to `polished_auto_export`.\")\n",
    "\n",
    "# Step 2: Clean `polished_auto_export` to remove `score` and `confidence`\n",
    "def clean_detections(sample, label_field):\n",
    "    \"\"\"Removes 'score' and 'confidence' fields to fix COCO export issues.\"\"\"\n",
    "    if sample[label_field] and sample[label_field].detections:\n",
    "        for det in sample[label_field].detections:\n",
    "            if hasattr(det, \"attributes\"):\n",
    "                det.attributes.pop(\"score\", None)  # Remove score field\n",
    "                det.attributes.pop(\"confidence\", None)  # Remove confidence field\n",
    "            if hasattr(det, \"score\"):\n",
    "                delattr(det, \"score\")  # Delete score if it exists\n",
    "            if hasattr(det, \"confidence\"):\n",
    "                delattr(det, \"confidence\")  # Delete confidence if it exists\n",
    "            det[\"iscrowd\"] = 0  # Ensure compatibility with COCO format\n",
    "    return sample\n",
    "\n",
    "# Apply cleaning function\n",
    "for sample in unique_view:\n",
    "    clean_detections(sample, \"polished_auto_export\")\n",
    "    sample.save()\n",
    "\n",
    "print(\"Cleaned `polished_auto_export` to remove conflicting fields.\")\n",
    "\n",
    "# Step 3: Export dataset in ...... format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7539177c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:        2025.03.17.13.05.22\n",
      "Media type:  image\n",
      "Num samples: 100\n",
      "Persistent:  False\n",
      "Tags:        []\n",
      "Sample fields:\n",
      "    id:                       fiftyone.core.fields.ObjectIdField\n",
      "    filepath:                 fiftyone.core.fields.StringField\n",
      "    tags:                     fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
      "    metadata:                 fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
      "    created_at:               fiftyone.core.fields.DateTimeField\n",
      "    last_modified_at:         fiftyone.core.fields.DateTimeField\n",
      "    categories_coco_id:       fiftyone.core.fields.IntField\n",
      "    categories_segmentations: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    segmentations:            fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    auto:                     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    polished_auto:            fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    polished_auto_export:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n"
     ]
    }
   ],
   "source": [
    "unique_view = dataset.select(results.unique_ids)\n",
    "session.view = unique_view\n",
    "\n",
    "new_dataset= unique_view.clone()\n",
    "print(new_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bca83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Export dataset in COCO format\n",
    "export_dir = \"100_unique_coffee_coco\"\n",
    "new_dataset.export(\n",
    "    export_dir=export_dir,\n",
    "    dataset_type = fo.types.COCODetectionDataset,\n",
    "    label_field=\"polished_auto_export\",  # Use cleaned duplicate field\n",
    "    include_media=True,  # Export images along with annotations\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f4d7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Export dataset in CVAT format\n",
    "export_dir = \"100_unique_coffee_cvat\"\n",
    "new_dataset.export(\n",
    "    export_dir=export_dir,\n",
    "    dataset_type=fo.types.CVATImageDataset,\n",
    "    label_field=\"polished_auto_export\",  # Use cleaned duplicate field\n",
    "    include_media=True,  # Export images along with annotations\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07f479cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring unsupported parameter 'include_media'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:fiftyone.utils.data.exporters:Ignoring unsupported parameter 'include_media'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fiftyone.utils.data.exporters:Exporting samples...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [164.3ms elapsed, 0s remaining, 608.7 docs/s]     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:eta.core.utils: 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [164.3ms elapsed, 0s remaining, 608.7 docs/s]     \n"
     ]
    }
   ],
   "source": [
    "# Step 3: Export dataset in CVAT format\n",
    "export_dir = \"100_unique_coffee_FO\"\n",
    "new_dataset.export(\n",
    "    export_dir=export_dir,\n",
    "    dataset_type=fo.types.FiftyOneDataset,\n",
    "    label_field=\"polished_auto_export\",  # Use cleaned duplicate field\n",
    "    include_media=True,  # Export images along with annotations\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48eda2fe",
   "metadata": {},
   "source": [
    "### Optional you can send images to CVAT for fixing annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7296cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to send the 100 uniqueness samples, but in this example we \n",
    "# Randomly select 5 samples to load to CVAT\n",
    "unique_5_view = unique_view.take(5)\n",
    "\n",
    "# A unique identifer for this run\n",
    "anno_key = \"segs_run\"\n",
    "\n",
    "# Upload the samples and launch CVAT\n",
    "anno_results = unique_5_view.annotate(\n",
    "    anno_key,\n",
    "    label_field=\"auto\",\n",
    "    label_type=\"instances\",\n",
    "    classes=[\"immature\", \"mature\", \"overmature\", \"semimature\"],\n",
    "    launch_editor=True,\n",
    "    url=\"https://cvat.ai\",\n",
    "    username=\"your_user_name\",\n",
    "    password=\"your_password\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe67988",
   "metadata": {},
   "source": [
    "![Image](https://github.com/user-attachments/assets/498d632a-c93a-41d7-82da-a81d6c29bbdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d29d46",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "- Fine-tune the SAM2 model for improved segmentation.\n",
    "- Integrate additional annotation tools with FiftyOne.\n",
    "- Explore active learning workflows for improving dataset quality."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coffee_workshop_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
