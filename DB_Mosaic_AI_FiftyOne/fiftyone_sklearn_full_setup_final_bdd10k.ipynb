{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afea604e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "# <img src=\"assets/voxel51_logo.png\" alt=\"Image2\" width=\"40\"/> FiftyOne + Vector Search\n",
    "This notebook demonstrates how to build a complete visual search workflow using **FiftyOne** and **Vector Search**.\n",
    "\n",
    "You will learn how to:\n",
    "- Load and index embeddings using FiftyOne\n",
    "- Query by image and text\n",
    "- Visualize results in the FiftyOne App\n",
    "\n",
    "ðŸ§  This integration helps you scale visual search over large datasets with a cloud-native vector database.\n",
    "\n",
    "ðŸ‘‰ As an example of vector search, see this official documentation [FiftyOne + Mosaic AI docs](https://docs.voxel51.com/integrations/mosaic.html)\n",
    "\n",
    "\n",
    "<img src=\"assets/mosaic_fiftyone_recipe.png\" alt=\"Image2\" width=\"600\"/>\n",
    "\n",
    "https://github.com/user-attachments/assets/2f5f21b3-5f42-4ab5-8e29-e1cac3e8eeb1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f37a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "#!pip install fiftyone torch torchvision python-dotenv mlflow umap-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15525903",
   "metadata": {},
   "source": [
    "Wait until this endpoint is ready, any action before that can create a 500 or 400 HTTP Error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3f8c95",
   "metadata": {},
   "source": [
    "## ðŸ“ Load the BDD100K Dataset and Launch FiftyOne\n",
    "We will use the `BDD100K` dataset from HuggingFace Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4195a6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fiftyone as fo\n",
    "\n",
    "# # Replace with your actual dataset name\n",
    "# dataset_name = \"BDD100K\"\n",
    "\n",
    "# # Check first if it exists\n",
    "# if dataset_name in fo.list_datasets():\n",
    "#     fo.delete_dataset(dataset_name)\n",
    "#     print(f\"âœ… Dataset '{dataset_name}' deleted successfully.\")\n",
    "# else:\n",
    "#     print(f\"âš ï¸ Dataset '{dataset_name}' does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defe3875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "import fiftyone.brain as fob\n",
    "\n",
    "import fiftyone as fo # base library and app\n",
    "import fiftyone.utils.huggingface as fouh # Hugging Face integration\n",
    "\n",
    "import os\n",
    "\n",
    "# Increase both connection and read timeout values (in seconds)\n",
    "os.environ[\"HF_HUB_DOWNLOAD_TIMEOUT\"] = \"60\"  # default is 10\n",
    "os.environ[\"HF_HUB_ETAG_TIMEOUT\"] = \"30\"      # metadata fetch timeout\n",
    "dataset = fouh.load_from_hub(\"dgural/bdd100k\", persistent=True) #, overwrite=True)\n",
    "\n",
    "# Define the new dataset name\n",
    "dataset_name = \"dgural/bdd100k\"\n",
    "\n",
    "# Check if the dataset exists\n",
    "if dataset_name in fo.list_datasets():\n",
    "    print(f\"Dataset '{dataset_name}' exists. Loading...\")\n",
    "    dataset = fo.load_dataset(dataset_name)\n",
    "else:\n",
    "    print(f\"Dataset '{dataset_name}' does not exist. Creating a new one...\")\n",
    "    # Clone the dataset with a new name and make it persistent\n",
    "    #dataset = dataset.clone(dataset_name, persistent=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19493819",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fo.list_datasets())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162ffed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = fo.launch_app(dataset, port=5151, auto=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e26231f",
   "metadata": {},
   "source": [
    "![Image](assets/fiftyone_APP.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5520efa5",
   "metadata": {},
   "source": [
    "## Using the SKLearn backend (By default)\n",
    "By default, calling ```compute_similarity()``` or ```sort_by_similarity()``` will use an sklearn backend.\n",
    "To use the Mosaic backend, simply set the optional backend parameter of ```compute_similarity()``` to ```mosaic```:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459abf73",
   "metadata": {},
   "source": [
    "## ðŸ§  Compute Embeddings and Index with SKLearn\n",
    "Now we compute a similarity index using the Mosaic backend. This will:\n",
    "- Use a CLIP model to generate embeddings\n",
    "- Compute visualization\n",
    "- Compute Similarity\n",
    "- Text promt the dataset, create a view, find mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e84292",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = foz.load_zoo_model(\"clip-vit-base32-torch\")\n",
    "embeddings = dataset.compute_embeddings(model, embeddings_field=\"embedding_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec50ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute visualization\n",
    "results = fob.compute_visualization(\n",
    "    dataset, embeddings=embeddings, seed=51, brain_key=\"bdd100k_key\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52a3d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Steps 2 and 3: Compute embeddings and create a similarity index\n",
    "sklear_idx = fob.compute_similarity(dataset, brain_index = \"test_idx\", model = \"clip-vit-base32-torch\", embeddings = \"embedding_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26620f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = fo.launch_app(dataset, port=5151, auto=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb61a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query by first image sample\n",
    "query = dataset.id[]\n",
    "view = dataset.sort_by_similarity(query, brain_key=\"similarity_index2\", k=10)\n",
    "session.view = view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3773c2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.reload()\n",
    "\n",
    "print(dataset)\n",
    "print(dataset.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cdd720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query by text prompt\n",
    "# DETECTIONS: bike  bus  car  motor  person  rider  traffic light  traffic sign  train  truck\n",
    "# WEATHER: overcast  foggy  rainy  snowy  undefined  partly cloudy  clear\n",
    "# SCENE: city street  gas stations  highway  parking lot  residential  tunnel \n",
    "# TIME OF DAY: daytime  night  dawn/dusk\n",
    "\n",
    "query_txt = \"bike\" \n",
    "view_txt = dataset.sort_by_similarity(query_txt, k=50, brain_key=\"embedding_key\")\n",
    "session.view = view_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15da7348",
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaic_index = fob.compute_similarity(\n",
    "    dataset,\n",
    "    model=\"clip-vit-base32-torch\",\n",
    "    backend=\"mosaic\",\n",
    "    brain_key=\"mosaic_index_5\",\n",
    "    index_name=\"fiftyone_index\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcaff1f",
   "metadata": {},
   "source": [
    "When you run ```compute_similarity()``` FiftyOne calcules embeddings on the fly, and you can see the vector values in the Databricks Schema that we previously setup.\n",
    "\n",
    "![Image](assets/databricks_view.png)\n",
    "\n",
    "https://github.com/user-attachments/assets/89ad39c8-baef-420b-a3a2-ccb074046b51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e9913a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve embeddings for a view\n",
    "ids = dataset.take(10).values(\"id\")\n",
    "embeddings, sample_ids, _ = mosaic_index.get_embeddings(sample_ids=ids)\n",
    "print(embeddings.shape)  # (10, 512)\n",
    "print(sample_ids.shape)  # (10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14863e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all embeddings from the MosaicSimilarityIndex\n",
    "embeddings, sample_ids, _ = similarity_index.get_embeddings()\n",
    "\n",
    "# Confirm shape\n",
    "print(\"Embeddings shape:\", embeddings.shape)  # (N, D) => N samples, D dimensions\n",
    "print(\"Sample IDs shape:\", sample_ids.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16126f4",
   "metadata": {},
   "source": [
    "### ðŸ“¦ Install `umap-learn`\n",
    "`umap-learn` is required to visualize high-dimensional embeddings in 2D or 3D.\n",
    "\n",
    "```bash\n",
    "pip install umap-learn\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d52e5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the visualization\n",
    "fob.compute_visualization(\n",
    "    dataset,                      # your FiftyOne dataset\n",
    "    embeddings=embeddings,        # the N x D matrix\n",
    "    brain_key=\"mosaic_viz\",       # identifier for visualization (name it!)\n",
    "    sample_ids=sample_ids         # make sure this matches the dataset\n",
    ")\n",
    "session = fo.launch_app(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dbbfd3",
   "metadata": {},
   "source": [
    "![Image](assets/emb.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6045e66",
   "metadata": {},
   "source": [
    "## Query the Similarity Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe58d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query by first image sample\n",
    "query = dataset.first().id\n",
    "view = dataset.sort_by_similarity(query, brain_key=\"mosaic_index_5\", k=10)\n",
    "session.view = view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d745b3b",
   "metadata": {},
   "source": [
    "![Image](assets/similarity.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cf6c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query by text prompt\n",
    "query_txt = \"a beach\"\n",
    "view_txt = dataset.sort_by_similarity(query_txt, k=50, brain_key=\"mosaic_index_5\")\n",
    "session.view = view_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9677086",
   "metadata": {},
   "source": [
    "![Image](assets/beach.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93f4064",
   "metadata": {},
   "source": [
    "## Cleanup (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec82790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete Mosaic index and run record\n",
    "mosaic_index.cleanup()\n",
    "dataset.delete_brain_run(\"mosaic_index\")\n",
    "#dataset.delete_brain_runs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fiftyone_DB_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
